# agent-template

åŸºæ–¼ LangChain çš„ AI Agent ç°¡æ˜“é–‹ç™¼æ¨¡æ¿

## ğŸŒŸ æ ¸å¿ƒç‰¹æ€§

**ç°¡æ½”è¨­è¨ˆ**ï¼šæ¡ç”¨ç›´æ¥åƒæ•¸åŒ–å‰µå»ºæ¨¡å¼ï¼Œç„¡éœ€è¤‡é›œçš„æ¨¡æ¿é…ç½®

- âœ… **é–‹ç®±å³ç”¨**ï¼šç›´æ¥ä½¿ç”¨åƒæ•¸å‰µå»º Agentï¼Œç„¡éœ€é å…ˆé…ç½®æ¨¡æ¿
- âœ… **éˆæ´»é…ç½®**ï¼šæ”¯æ´å®Œå…¨è‡ªå®šç¾©çš„ Agent é…ç½®
- âœ… **é¡å‹å®‰å…¨**ï¼šåŸºæ–¼ Pydantic çš„å¼·é¡å‹é©—è­‰
- âœ… **æ¨™æº–å”è­°**ï¼šæ”¯æ´ MCP (Model Context Protocol) å·¥å…·æ•´åˆ

**æ¶æ§‹ç‰¹é»**ï¼š

```python
agent = factory.create_agent(
    name="ç ”ç©¶åŠ©ç†",
    description="å°ˆæ¥­ç ”ç©¶å’Œåˆ†æå°ˆå®¶",
    system_prompt="ä½ æ˜¯ä¸€ä½å°ˆæ¥­ç ”ç©¶å“¡...",
    model=llm.model,
    tools=["web_search", "pdf_reader"],
    max_iterations=10,
    temperature=0.7
)
```

## ğŸŒŸ æ¶æ§‹æ˜¯å•¥?

### ğŸ§  ReAct æ¡†æ¶

- **æ¨ç†å¾ªç’°** - æ€è€ƒ â†’ è¡Œå‹• â†’ è§€å¯Ÿ â†’ åæ€çš„æ™ºèƒ½æ±ºç­–æµç¨‹
- **å·¥å…·æ•´åˆ** - ç„¡ç¸«æ¥å…¥å„ç¨®å¤–éƒ¨å·¥å…·å’Œ API
- **ä¸Šä¸‹æ–‡è¨˜æ†¶** - ç¶­è­·å°è©±ç‹€æ…‹å’ŒåŸ·è¡Œæ­·å²
- **éŒ¯èª¤æ¢å¾©** - è‡ªå‹•éŒ¯èª¤è™•ç†å’Œé‡è©¦æ©Ÿåˆ¶

### ğŸ”§ æ¨™æº–åŒ–å·¥å…·ç”Ÿæ…‹

- **MCP å”è­°æ”¯æ´** - Model Context Protocol æ¨™æº–åŒ–å·¥å…·æ¥å£
- **çµ±ä¸€å·¥å…·ç®¡ç†** - å·¥å…·è¨»å†Šã€ç™¼ç¾ã€èª¿ç”¨çš„å®Œæ•´ç”Ÿå‘½é€±æœŸ
- **æ¨¡å¡ŠåŒ–è¨­è¨ˆ** - è¼•é¬†æ“´å±•æ–°å·¥å…·å’ŒåŠŸèƒ½
- **å®‰å…¨åŸ·è¡Œ** - éš”é›¢ç’°å¢ƒç¢ºä¿ç³»çµ±å®‰å…¨

### ğŸ‘¥ å¤š Agent å”ä½œ

- **åœ˜éšŠç·¨æ’** - æ”¯æ´å¤šå€‹å°ˆæ¥­ Agent å”åŒå·¥ä½œ
- **ç‹€æ…‹åŒæ­¥** - Agent é–“è³‡è¨Šå…±äº«å’Œå”èª¿
- **å·¥ä½œæµç®¡ç†** - åŸºæ–¼ LangGraph çš„è¤‡é›œæµç¨‹ç·¨æ’
- **å½ˆæ€§çµ„å»º** - æ ¹æ“šä»»å‹™éœ€æ±‚å‹•æ…‹çµ„å»ºåœ˜éšŠ

---

## ğŸš€ å¿«é€Ÿé–‹å§‹

### ğŸ› ï¸ ç’°å¢ƒè¨­ç½®

**1. å…‹éš†å°ˆæ¡ˆ**

```bash
git clone https://github.com/your-username/agent-template.git
cd agent-template
```

**2. å®‰è£ä¾è³´**

```bash
# ä½¿ç”¨ uvï¼ˆæ¨è–¦ï¼‰
uv sync

# æˆ–ä½¿ç”¨ pip
pip install -r requirements.txt
```

**3. ç’°å¢ƒé…ç½®**

åœ¨ `src/` ç›®éŒ„ä¸‹å‰µå»º `.env` æ–‡ä»¶ï¼Œåƒè€ƒ [.env.example](src/.env.example)ï¼š

```env
# é¸æ“‡å…¶ä¸­ä¸€å€‹ LLM æä¾›å•†é…ç½®

# OpenAI
OPENAI_API_KEY=sk-your-key-here

# Anthropic Claude
ANTHROPIC_API_KEY=sk-ant-your-key-here

# Google Gemini
GOOGLE_API_KEY=your-google-api-key

# æœ¬åœ° Ollama (é è¨­)
OLLAMA_BASE_URL=http://localhost:11434

# Azure OpenAI
AZURE_OPENAI_API_KEY=your-azure-api-key
AZURE_OPENAI_ENDPOINT=your-azure-endpoint
```

### âš¡ åŸºç¤ä½¿ç”¨

**ç«‹å³é–‹å§‹**

```bash
cd src
uv run test.py
```

## ğŸ”§ æ ¸å¿ƒçµ„ä»¶

### LLM æä¾›å•†

æ”¯æ´å¤šç¨®èªè¨€æ¨¡å‹ï¼š

```python
# OpenAI GPT æ¨¡å‹
llm = LLM_Provider(model="gpt-4", provider="openai")

# Anthropic Claude æ¨¡å‹
llm = LLM_Provider(model="claude-3-haiku-20240307", provider="anthropic")

# Google Gemini æ¨¡å‹
llm = LLM_Provider(model="gemini-pro", provider="google")

# æœ¬åœ° Ollama æ¨¡å‹
llm = LLM_Provider(model="qwen3:0.6b", provider="ollama")

# DeepSeek æ¨¡å‹
llm = LLM_Provider(model="deepseek-r1", provider="deepseek")
```

### Agent å·¥å» 

```python
from agent import AgentFactory, LLM_Provider, ToolManager

# åˆå§‹åŒ– LLM æä¾›è€… (LLM_Provider)
llm = LLM_Provider(model="qwen3:0.6b", provider="ollama")

# å‰µå»ºå…·å‚™å·¥å…·ç®¡ç†çš„å·¥å»  (AgentFactory)
tool_manager = ToolManager()
factory = AgentFactory(tool_manager=tool_manager)

agent = factory.create_agent(
    name="å°ˆå®¶åŠ©ç†",
    description="é ˜åŸŸå°ˆå®¶",
    system_prompt="è©³ç´°çš„ç³»çµ±æç¤º...",
    model=llm.model,
    tools=["calculator", "web_search"],
    max_iterations=10,
    temperature=0.7
)

# ä½¿ç”¨è‡ªå®šç¾©å‰µå»º (ä½¿ç”¨ AgentConfig å…ˆå®šç¾© configï¼Œå†ä½¿ç”¨ AgentFactory å‰µå»º)
from agent.types import AgentConfig

config = AgentConfig(
    name="è‡ªå®šç¾©åŠ©ç†",
    description="å®Œå…¨è‡ªå®šç¾©çš„åŠ©ç†",
    system_prompt="ä½ æ˜¯ä¸€å€‹è‡ªå®šç¾©åŠ©ç†...",
    tools=["custom_tool"],
    max_iterations=15,
    temperature=0.5
)

custom_agent = factory.create_custom_agent(config, llm.model)

# å‰µå»ºåœ˜éšŠ
team_config = {
    "researcher": {
        "name": "ç ”ç©¶å°ˆå®¶",
        "description": "å°ˆæ¥­ç ”ç©¶å“¡",
        "system_prompt": "ç ”ç©¶å°ˆç”¨æç¤º...",
        "tools": ["web_search"],
        "max_iterations": 15
    },
    "analyst": {
        "name": "æ•¸æ“šåˆ†æå¸«",
        "description": "æ•¸æ“šåˆ†æå°ˆå®¶",
        "system_prompt": "åˆ†æå°ˆç”¨æç¤º...",
        "tools": ["calculator", "data_processor"],
        "max_iterations": 12
    }
}

team = factory.create_multi_agent_team(team_config, llm.model)
```

### MCP å·¥å…·æ•´åˆ

```python
# MCP é…ç½®æ–‡ä»¶ (mcp_config.json)
{
  "mcpServers": {
    "fetch": {
      "command": "uvx",
      "args": ["mcp-server-fetch"],
      "transport": "stdio"
    },
    "everything": {
      "command": "npx",
      "args": ["-y", "@modelcontextprotocol/server-everything"],
      "transport": "stdio"
    }
  }
}


# ç¨‹å¼ä¸­ä½¿ç”¨
import json
import os

from agent import MCPClientService, ToolManager

# åˆå§‹åŒ–å·¥å…·ç®¡ç†å™¨
tool_manager = ToolManager()

# åˆå§‹åŒ– MCP å®¢æˆ¶ç«¯æœå‹™
config_path = os.path.join(os.path.dirname(__file__), "mcp_config.json")
try:
    with open(config_path, 'r', encoding='utf-8') as f:
        mcp_config = json.load(f)
        servers = list(mcp_config['mcpServers'].keys())
        print(f"âœ… å·²è¼‰å…¥ MCP é…ç½®: {servers}")
except Exception as e:
    print(f"âš ï¸  ç„¡æ³•è¼‰å…¥ MCP é…ç½®: {e}")
    print("â„¹ï¸  å°‡ä½¿ç”¨ç©ºé…ç½®ç¹¼çºŒ")
    mcp_config = {"mcpServers": {}}

mcp_client = MCPClientService(mcp_config["mcpServers"], tool_manager)
available_tools = mcp_client.get_tools()
print(f"å¯ç”¨å·¥å…·: {[tool.name for tool in available_tools]}")
```

### ğŸ¯ æ ¸å¿ƒç”¨æ³•

---

#### 1. å‰µå»ºå–®ä¸€ Agent

```python
import asyncio
from agent import AgentFactory, LLM_Provider

async def main():
    # åˆå§‹åŒ– LLM æä¾›å•†
    llm = LLM_Provider(
        model="qwen3:0.6b",  # æˆ– "gpt-4", "claude-3-haiku-20240307"
        provider="ollama"    # æˆ– "openai", "anthropic", "google"
    )

    # å‰µå»ºä»£ç†å·¥å» 
    factory = AgentFactory()

    # å‰µå»ºé€šç”¨åŠ©ç†
    agent = factory.create_agent(
        name="æˆ‘çš„åŠ©ç†",
        description="ä¸€å€‹æœ‰ç”¨çš„AIåŠ©ç†",
        system_prompt="""ä½ æ˜¯ä¸€ä½æ™ºèƒ½åŠ©ç†ï¼Œå…·å‚™ä»¥ä¸‹èƒ½åŠ›ï¼š

**å·¥ä½œåŸå‰‡ï¼š**
- æŒ‰ç…§ æ€è€ƒâ†’è¡Œå‹•â†’è§€å¯Ÿâ†’åæ€ çš„å¾ªç’°è™•ç†ä»»å‹™
- ä½¿ç”¨ç¹é«”ä¸­æ–‡èˆ‡ç”¨æˆ¶æºé€š
- ä¸»å‹•ä½¿ç”¨å¯ç”¨å·¥å…·å¢å¼·å›ç­”å“è³ª
- æ‰¿èªä¸ç¢ºå®šæ€§ä¸¦å°‹æ±‚æ¾„æ¸…

è«‹æä¾›æº–ç¢ºã€æœ‰ç”¨ä¸”å®Œæ•´çš„å›ç­”ã€‚""",
        model=llm.model,
        tools=[],  # å¯æ·»åŠ å·¥å…·åç¨±åˆ—è¡¨
        max_iterations=10,
        temperature=0.7
    )

    # åˆå§‹åŒ–ä¸¦ä½¿ç”¨
    await agent.initialize()
    response = await agent.process_message("ä½ å¥½ï¼è«‹ä»‹ç´¹ä¸€ä¸‹ä½ çš„åŠŸèƒ½ã€‚")
    print(f"åŠ©ç†å›æ‡‰: {response}")

if __name__ == "__main__":
    asyncio.run(main())
```

#### 2. å¤š Agent å”ä½œ

```python
import asyncio

from agent import AgentFactory, LLM_Provider


async def multi_agent_example():
    llm = LLM_Provider(model="qwen3:0.6b", provider="ollama")
    factory = AgentFactory()

    # å‰µå»ºç ”ç©¶å“¡
    researcher = factory.create_agent(
        name="ç ”ç©¶å“¡",
        description="å°ˆæ¥­ç ”ç©¶å’Œè³‡è¨Šåˆ†æå°ˆå®¶",
        system_prompt="""ä½ æ˜¯ä¸€ä½å°ˆæ¥­ç ”ç©¶å“¡ï¼Œå°ˆæ³¨æ–¼ï¼š
- ç³»çµ±æ€§è³‡è¨Šæœé›†
- æ‰¹åˆ¤æ€§åˆ†æ
- å¯é è³‡æ–™é©—è­‰
- çµæ§‹åŒ–å ±å‘Šæ’°å¯«

è«‹ä¿æŒå­¸è¡“åš´è¬¹æ€§ã€‚""",
        model=llm.model,
        tools=["web_search", "pdf_reader"],
        max_iterations=15
    )

    # å‰µå»ºå¯«ä½œåŠ©æ‰‹
    writer = factory.create_agent(
        name="å¯«ä½œåŠ©æ‰‹",
        description="å°ˆæ¥­å…§å®¹å‰µä½œå’Œç·¨è¼¯å°ˆå®¶",
        system_prompt="""ä½ æ˜¯ä¸€ä½å°ˆæ¥­å¯«ä½œåŠ©æ‰‹ï¼Œå°ˆæ³¨æ–¼ï¼š
- å…§å®¹çµæ§‹è¦åŠƒ
- èªè¨€è¡¨é”å„ªåŒ–
- è®€è€…é«”é©—è€ƒé‡
- å“è³ªæ§åˆ¶æª¢æŸ¥

è«‹å‰µä½œå¼•äººå…¥å‹çš„å…§å®¹ã€‚""",
        model=llm.model,
        tools=["grammar_checker", "style_analyzer"],
        max_iterations=10
    )

    # åˆå§‹åŒ–ä»£ç†
    await researcher.initialize()
    await writer.initialize()

    # å”ä½œç”Ÿæˆå ±å‘Š
    research_topic = "äººå·¥æ™ºæ…§åœ¨æ•™è‚²é ˜åŸŸçš„æ‡‰ç”¨"

    # ç¬¬ä¸€éšæ®µï¼šç ”ç©¶
    research_data = await researcher.process_message(
        f"è«‹æ·±å…¥ç ”ç©¶ {research_topic}ï¼Œæä¾›è©³ç´°çš„åˆ†æå ±å‘Š"
    )

    # ç¬¬äºŒéšæ®µï¼šå¯«ä½œ
    final_report = await writer.process_message(
        f"åŸºæ–¼ä»¥ä¸‹ç ”ç©¶è³‡æ–™ï¼Œæ’°å¯«ä¸€ä»½æ˜“è®€çš„å ±å‘Šï¼š\n\n{research_data}"
    )

    return final_report

async def main():
    report = await multi_agent_example()
    print(report)

if __name__ == "__main__":
    asyncio.run(main())
```

#### 3. ä½¿ç”¨å·¥å…·ç®¡ç†å™¨å’Œ MCP

```python
import asyncio
import json

from agent import AgentFactory, LLM_Provider, MCPClientService, ToolManager


async def tool_integration_example():
    # è¼‰å…¥ MCP é…ç½®
    with open("mcp_config.json", 'r') as f:
        mcp_config = json.load(f)

    # åˆå§‹åŒ–å·¥å…·ç®¡ç†å™¨
    tool_manager = ToolManager()

    # åˆå§‹åŒ– MCP å®¢æˆ¶ç«¯
    mcp_client = MCPClientService(
        mcp_config["mcpServers"],
        tool_manager
    )

    # åˆå§‹åŒ– LLM
    llm = LLM_Provider(model="qwen3:0.6b", provider="ollama")

    # å‰µå»ºå…·å‚™å·¥å…·èƒ½åŠ›çš„ Agent
    factory = AgentFactory(tool_manager=tool_manager)

    agent = factory.create_agent(
        name="å·¥å…·å°ˆå®¶",
        description="èƒ½å¤ ä½¿ç”¨å„ç¨®å·¥å…·çš„å°ˆæ¥­åŠ©ç†",
        system_prompt="ä½ å¯ä»¥ä½¿ç”¨å„ç¨®å·¥å…·ä¾†å®Œæˆä»»å‹™ã€‚æ ¹æ“šéœ€è¦é¸æ“‡åˆé©çš„å·¥å…·ã€‚",
        model=llm.model,
        tools=tool_manager.get_tool_names(),  # ä½¿ç”¨æ‰€æœ‰å¯ç”¨å·¥å…·
        max_iterations=10
    )

    await agent.initialize()
    return agent

async def main():
    agent = await tool_integration_example()
    result = await agent.process_message("è«‹ç”¨åˆé©çš„å·¥å…·æŸ¥è©¢ HackerNews (https://news.ycombinator.com/) çš„æœ€æ–°å…§å®¹")
    print(result)

if __name__ == "__main__":
    asyncio.run(main())
```

> ğŸ’¡ **æƒ³äº†è§£æ›´å¤šä½¿ç”¨æ–¹å¼ï¼Ÿ**
> æŸ¥çœ‹ **[è©³ç´°ä½¿ç”¨æŒ‡å—](USAGE_GUIDE.md)** ç²å–ï¼š

---

## ğŸ“ å°ˆæ¡ˆæ¶æ§‹

```
src/
â”œâ”€â”€ agent/                      # æ ¸å¿ƒä»£ç†æ¨¡çµ„
â”‚   â”œâ”€â”€ __init__.py            # æ¨¡çµ„åˆå§‹åŒ–
â”‚   â”œâ”€â”€ core/                  # æ ¸å¿ƒåŠŸèƒ½
â”‚   â”‚   â”œâ”€â”€ agent_factory.py   # ä»£ç†å·¥å» 
â”‚   â”‚   â”œâ”€â”€ base_agent.py      # åŸºç¤ä»£ç†é¡åˆ¥
â”‚   â”‚   â””â”€â”€ llm_factory.py     # LLM æä¾›å•†å·¥å» 
â”‚   â”œâ”€â”€ tools/                 # å·¥å…·ç®¡ç†
â”‚   â”‚   â”œâ”€â”€ mcp_client.py      # MCP å®¢æˆ¶ç«¯æœå‹™
â”‚   â”‚   â””â”€â”€ tool_manager.py    # çµ±ä¸€å·¥å…·ç®¡ç†å™¨
â”‚   â”œâ”€â”€ types/                 # é¡å‹å®šç¾©
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â””â”€â”€ agent_types.py     # ä»£ç†ç›¸é—œé¡å‹
â”‚   â””â”€â”€ utils/                 # å·¥å…·å‡½æ•¸
â”‚       â””â”€â”€ config_loader.py   # é…ç½®è¼‰å…¥å™¨
â”œâ”€â”€ config/                    # é…ç½®ç®¡ç†
â”‚   â”œâ”€â”€ config_manager.py      # é…ç½®ç®¡ç†å™¨
â”‚   â””â”€â”€ env.py                 # ç’°å¢ƒè®Šæ•¸è¼‰å…¥
â”œâ”€â”€ test.py                    # å¿«é€Ÿæ¸¬è©¦ç¯„ä¾‹
â”œâ”€â”€ pyproject.toml            # å°ˆæ¡ˆä¾è³´é…ç½®
â””â”€â”€ mcp_config.json           # MCP å·¥å…·é…ç½®
```

### æ¶æ§‹å±¤æ¬¡

- **æ ¸å¿ƒå±¤ (Core Layer)**: AgentFactoryã€BaseAgent/ReactAgentã€LLM_Provider
- **å·¥å…·å±¤ (Tool Layer)**: ToolManagerã€MCPClientService
- **é¡å‹å±¤ (Type Layer)**: AgentTypes

## ğŸ“¦ ä¾è³´é …ç›®

ä¸»è¦ä¾è³´ï¼š

- `langgraph` - å·¥ä½œæµç·¨æ’æ¡†æ¶
- `langchain` - LLM æŠ½è±¡å±¤
- `pydantic` - è³‡æ–™é©—è­‰
- `mcp` - Model Context Protocol æ”¯æ´

è©³è¦‹ `pyproject.toml` æ–‡ä»¶ã€‚

---

## ğŸ“„ æˆæ¬Šä¸€ä¸‹?

[LICENSE](LICENSE)
